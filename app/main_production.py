# app/main_production.py
from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import logging
import time
import uuid
from contextlib import asynccontextmanager

from app.core.config import settings
from app.services.deepseek_processor import deepseek_processor
from app.models.schemas import TextRequest, ProcessResult

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)

@asynccontextmanager
async def lifespan(app: FastAPI):
    # å¯åŠ¨æ—¶æ£€æŸ¥
    logger.info("ğŸš€ AIå­¦æœ¯æ¶¦è‰²ç³»ç»Ÿå¯åŠ¨")
    logger.info(f"âœ… ç«å±±å¼•æ“ API: {'å·²é…ç½®' if settings.ark_api_key else 'æœªé…ç½®'}")
    logger.info(f"âœ… æ¨¡å‹: {settings.deepseek_model_id}")
    yield
    # å…³é—­æ—¶çš„æ¸…ç†å·¥ä½œ
    logger.info("ğŸ”’ åº”ç”¨å…³é—­")

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="AIå­¦æœ¯æ¶¦è‰²ç³»ç»Ÿ",
    description="åŸºäºç«å±±å¼•æ“DeepSeek-R1çš„ä¸“ä¸šå­¦æœ¯æ–‡æœ¬æ¶¦è‰²æœåŠ¡",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc",
    lifespan=lifespan
)

# CORSä¸­é—´ä»¶é…ç½®ï¼ˆé€‚é…æ‰€æœ‰å‰ç«¯ï¼‰
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # å¼€å‘é˜¶æ®µå…è®¸æ‰€æœ‰æ¥æº
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# è¯·æ±‚æ—¥å¿—ä¸­é—´ä»¶
@app.middleware("http")
async def log_requests(request, call_next):
    request_id = str(uuid.uuid4())[:8]
    start_time = time.time()
    
    logger.info(f"ğŸ“ è¯·æ±‚ [{request_id}] {request.method} {request.url.path}")
    
    response = await call_next(request)
    
    process_time = time.time() - start_time
    logger.info(f"âœ… å“åº” [{request_id}] {response.status_code} - {process_time:.2f}s")
    
    response.headers["X-Request-ID"] = request_id
    return response

# æ ¹è·¯å¾„
@app.get("/")
async def root():
    return {
        "message": "AIå­¦æœ¯æ¶¦è‰²ç³»ç»Ÿ",
        "description": "ä¸“ä¸šçš„å­¦æœ¯æ–‡æœ¬æ¶¦è‰²ã€AIæ£€æµ‹å’Œé£æ ¼è½¬æ¢æœåŠ¡",
        "version": "1.0.0",
        "api_docs": "/docs",
        "status": "è¿è¡Œä¸­",
        "powered_by": "ç«å±±å¼•æ“ DeepSeek-R1"
    }

# å¥åº·æ£€æŸ¥
@app.get("/api/v1/health")
async def health_check():
    return {
        "status": "healthy",
        "service": "ai-academic-polish",
        "api_provider": "ark_deepseek_r1",
        "model": settings.deepseek_model_id,
        "timestamp": int(time.time()),
        "version": "1.0.0"
    }

# è·å–æ”¯æŒçš„é£æ ¼
@app.get("/api/v1/styles")
async def get_styles():
    return {
        "styles": [
            {
                "id": "academic",
                "name": "å­¦æœ¯è®ºæ–‡",
                "description": "æé«˜ä¸“ä¸šæ€§å’Œä¸¥è°¨æ€§ï¼Œé€‚åˆå­¦æœ¯è®ºæ–‡å’Œç ”ç©¶æŠ¥å‘Š"
            },
            {
                "id": "formal", 
                "name": "æ­£å¼æ–‡ä½“",
                "description": "åº„é‡å¾—ä½“çš„è¯­è¨€é£æ ¼ï¼Œé€‚åˆæ­£å¼æ–‡æ¡£å’Œå•†åŠ¡åœºåˆ"
            },
            {
                "id": "casual",
                "name": "é€šä¿—æ˜“æ‡‚", 
                "description": "ç®€æ´æ˜äº†çš„è¡¨è¾¾æ–¹å¼ï¼Œä¾¿äºæ™®é€šè¯»è€…ç†è§£"
            },
            {
                "id": "creative",
                "name": "åˆ›æ„è¡¨è¾¾",
                "description": "æ–°é¢–æœ‰è¶£çš„è¡¨è¾¾æ–¹å¼ï¼Œå¢å¼ºæ–‡æœ¬å¸å¼•åŠ›"
            }
        ]
    }

# ä¸»è¦æ–‡æœ¬å¤„ç†æ¥å£
@app.post("/api/v1/process", response_model=ProcessResult)
async def process_text(request: TextRequest):
    # ç¡®ä¿é£æ ¼ä¸ä¸ºç©º
    style = request.style or "academic"
    logger.info(f"ğŸ”„ å¤„ç†è¯·æ±‚: {len(request.content)}å­—ç¬¦, é£æ ¼: {style}")
    
    try:
        # è°ƒç”¨AIå¤„ç† - æ·»åŠ è¯¦ç»†æ—¥å¿—å’ŒéªŒè¯
        logger.debug(f"å¼€å§‹å¤„ç†æ–‡æœ¬ï¼Œé•¿åº¦: {len(request.content)}ï¼Œé£æ ¼: {style}")
        
        # æ·»åŠ è¾“å…¥éªŒè¯
        if not request.content or not isinstance(request.content, str):
            logger.error("æ— æ•ˆçš„è¾“å…¥å†…å®¹")
            raise HTTPException(status_code=400, detail="è¾“å…¥å†…å®¹ä¸èƒ½ä¸ºç©ºä¸”å¿…é¡»æ˜¯å­—ç¬¦ä¸²")
        
        if style not in ["academic", "formal", "casual", "creative"]:
            logger.warning(f"æœªçŸ¥é£æ ¼: {style}ï¼Œå°†ä½¿ç”¨é»˜è®¤å­¦æœ¯é£æ ¼")
            style = "academic"
        
        # è°ƒç”¨AIå¤„ç†
        result = await deepseek_processor.process_text(request.content, style)
        
        # éªŒè¯ç»“æœç»“æ„
        required_keys = ["text", "ai_score", "processing_time"]
        if not all(key in result for key in required_keys):
            missing = [k for k in required_keys if k not in result]
            logger.error(f"AIè¿”å›ç»“æœç¼ºå°‘å¿…è¦å­—æ®µ: {missing}")
            raise HTTPException(status_code=502, detail="AIæœåŠ¡è¿”å›æ— æ•ˆå“åº”")
        
        # æ„å»ºå“åº” - æ·»åŠ æ›´ä¸¥æ ¼çš„ç±»å‹æ£€æŸ¥
        try:
            response = ProcessResult(
                original_text=request.content,
                processed_text=str(result["text"]),  # ç¡®ä¿æ˜¯å­—ç¬¦ä¸²
                reasoning_content=str(result.get("reasoning", "æ— ")),  # é»˜è®¤å€¼æ›´æ˜ç¡®
                ai_probability=float(result["ai_score"]),  # ç¡®ä¿æ˜¯æµ®ç‚¹æ•°
                processing_time=float(result["processing_time"]),  # ç¡®ä¿æ˜¯æµ®ç‚¹æ•°
                style_used=style,
                api_used=str(result.get("api_used", "unknown"))  # ç¡®ä¿æ˜¯å­—ç¬¦ä¸²
            )
        except (ValueError, TypeError) as e:
            logger.error(f"å“åº”æ•°æ®è½¬æ¢é”™è¯¯: {str(e)}")
            raise HTTPException(status_code=502, detail="AIæœåŠ¡è¿”å›æ•°æ®æ ¼å¼é”™è¯¯")
        
        # æ·»åŠ è¯¦ç»†çš„æˆåŠŸæ—¥å¿—
        logger.info(
            f"âœ… å¤„ç†å®Œæˆ - å­—ç¬¦æ•°: {len(request.content)}â†’{len(response.processed_text)} "
            f"è€—æ—¶: {response.processing_time:.2f}s "
            f"AIæ¦‚ç‡: {response.ai_probability:.2f}"
        )
        
        # è¿”å›å“åº”å‰æ·»åŠ è°ƒè¯•æ—¥å¿—
        if logger.isEnabledFor(logging.DEBUG):
            logger.debug(f"å®Œæ•´å“åº”: {response.json(exclude={'original_text'})[:200]}...")
        
        return response
        
    except HTTPException:
        raise  # ç›´æ¥æŠ›å‡ºå·²æœ‰çš„HTTPå¼‚å¸¸
        
    except Exception as e:
        logger.exception("å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°æœªé¢„æœŸé”™è¯¯")  # è¿™ä¼šè®°å½•å®Œæ•´çš„å †æ ˆè·Ÿè¸ª
        raise HTTPException(
            status_code=500,
            detail=f"å¤„ç†å¤±è´¥: {str(e)}"
        )

# AIæ£€æµ‹æ¥å£
@app.post("/api/v1/detect")
async def detect_ai_text(request: TextRequest):
    """
    AIæ–‡æœ¬æ£€æµ‹æ¥å£
    
    åˆ†ææ–‡æœ¬çš„AIç”Ÿæˆæ¦‚ç‡
    """
    logger.info(f"ğŸ” AIæ£€æµ‹è¯·æ±‚: {len(request.content)}å­—ç¬¦")
    
    try:
        # è¿™é‡Œå¯ä»¥é›†æˆä¸“é—¨çš„AIæ£€æµ‹æ¨¡å‹
        # æš‚æ—¶ä½¿ç”¨ç®€å•çš„æ£€æµ‹é€»è¾‘
        result = await deepseek_processor.process_text(request.content, "academic")
        
        return {
            "content": request.content,
            "ai_probability": result["ai_score"],
            "confidence_level": "medium" if result["ai_score"] > 0.5 else "low",
            "analysis": {
                "pattern_score": result["ai_score"] * 0.6,
                "complexity_score": result["ai_score"] * 0.4,
                "semantic_score": result["ai_score"] * 0.5
            },
            "processing_time": result["processing_time"]
        }
        
    except Exception as e:
        logger.error(f"âŒ æ£€æµ‹å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail="AIæ£€æµ‹å¤±è´¥")

# æ‰¹é‡å¤„ç†æ¥å£
@app.post("/api/v1/batch")
async def batch_process(
    requests: list[TextRequest], 
    background_tasks: BackgroundTasks
):
    """
    æ‰¹é‡æ–‡æœ¬å¤„ç†æ¥å£
    
    æ”¯æŒåŒæ—¶å¤„ç†å¤šä¸ªæ–‡æœ¬
    """
    if len(requests) > 10:
        raise HTTPException(status_code=400, detail="æ‰¹é‡å¤„ç†æœ€å¤šæ”¯æŒ10ä¸ªæ–‡æœ¬")
    
    logger.info(f"ğŸ“¦ æ‰¹é‡å¤„ç†: {len(requests)}ä¸ªæ–‡æœ¬")
    
    try:
        results = []
        for i, req in enumerate(requests):
            logger.info(f"ğŸ”„ å¤„ç†ç¬¬{i+1}ä¸ªæ–‡æœ¬...")
            style = req.style or "academic"
            result = await deepseek_processor.process_text(req.content, style)
            
            results.append({
                "index": i,
                "original_text": req.content,
                "processed_text": result["text"],
                "ai_probability": result["ai_score"],
                "processing_time": result["processing_time"],
                "style": req.style
            })
        
        total_time = sum(r["processing_time"] for r in results)
        logger.info(f"âœ… æ‰¹é‡å¤„ç†å®Œæˆ: {total_time:.2f}s")
        
        return {
            "total_count": len(results),
            "total_time": total_time,
            "results": results
        }
        
    except Exception as e:
        logger.error(f"âŒ æ‰¹é‡å¤„ç†å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail="æ‰¹é‡å¤„ç†å¤±è´¥")

# é”™è¯¯å¤„ç†
@app.exception_handler(HTTPException)
async def http_exception_handler(request, exc):
    logger.error(f"HTTPé”™è¯¯: {exc.status_code} - {exc.detail}")
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error": True,
            "status_code": exc.status_code,
            "message": exc.detail,
            "timestamp": int(time.time())
        }
    )

@app.exception_handler(Exception)
async def general_exception_handler(request, exc):
    logger.error(f"æœªå¤„ç†çš„é”™è¯¯: {str(exc)}")
    return JSONResponse(
        status_code=500,
        content={
            "error": True,
            "status_code": 500,
            "message": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯",
            "timestamp": int(time.time())
        }
    )

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "app.main_production:app",
        host="0.0.0.0",
        port=8000,
        reload=settings.debug
    )